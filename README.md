# Text-to-Image Generation with Stable Diffusion üé®üñºÔ∏è

## Project Overview

This project implements text-to-image generation using Stable Diffusion, a state-of-the-art deep learning model for synthesizing high-quality images from textual descriptions. It leverages Python and deep learning frameworks to generate realistic images based on user input, showcasing the power of generative AI.

### Key Features

Text-to-Image Conversion ‚Äì Generates high-quality images from textual prompts.

Stable Diffusion Implementation ‚Äì Uses pre-trained models for realistic image synthesis.

Customization ‚Äì Allows fine-tuning of parameters to control output image style and quality.

GPU Acceleration ‚Äì Optimized for CUDA-enabled GPUs for faster inference.

### Technologies Used

Python, Stable Diffusion, Hugging Face Diffusers, PyTorch, OpenAI CLIP

### How to Run the Project

Clone this repository:

git clone https://github.com/rahulpadwani/Text-to-Image-Stable-diffusion-Project.git

Install dependencies:

pip install -r requirements.txt

Run the script to generate images:

python generate.py --prompt "A futuristic cityscape at sunset"

## Project Insights

Explored the capabilities of Stable Diffusion for creative AI applications.

Fine-tuned image generation settings for enhanced visual quality.

Leveraged GPU acceleration for efficient model inference
